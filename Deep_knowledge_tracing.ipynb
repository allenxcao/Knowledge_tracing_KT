{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Deep knowledge tracing (DKT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background:\n",
    "\n",
    "Bayesian knowledge tracing is the most popular approach to model knowledge state of learners: e.g. whether some knowledge, skills or contexts are mastery or not. BKT models a learner’s latent knowledge state as a set of binary variables, each of which represents understanding or non-understanding of a single concept. The original model formulation assumed that once a skill is learned it is never forgotten. Recent extensions to this model include contextualization of guessing and slipping estimates, estimating prior knowledge for individual learners, and estimating problem difficulty.\n",
    "\n",
    "With or without such extensions, Knowledge Tracing suffers from several difficulties. First, the binary representation of student understanding may be unrealistic. Second, the meaning of the hidden variables and their mappings onto exercises can be ambiguous, rarely meeting the model’s expectation of a single concept per exercise. Several techniques have been developed to create and refine concept categories and concept-exercise mappings. The current gold standard, Cognitive Task Analysis is an arduous and iterative process where domain experts ask learners to talk through their thought processes while solving problems. Finally, the binary response data used to model transitions imposes a limit on the kinds of exercises that can be modeled.\n",
    "\n",
    "Recurrent Neural Networks (RNNs) to model student learning has been explored by the paper: Deep knowledge tracing. The RNN family of models has important advantages over previous methods in that they do not require the explicit encoding of human domain knowledge, and can capture more complex representations of student knowledge. Using neural networks results in substantial improvements in prediction performance on a range of knowledge tracing datasets. Moreover, the learned model can be used for intelligent curriculum design and allows straightforward interpretation and discovery of structure in student tasks. These results suggest a promising new line of research for knowledge tracing and an exemplary application task for RNNs.\n"
   ]
  },
  {
   "attachments": {
    "rnn.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "#### Recurrent Neural Networks\n",
    "Traditional Recurrent Neural Networks (RNNs) map an input sequence of vectors $x_1,x_2,…,x_T$, to an output sequence of vectors$y_1,y_2,…,y_T$. This is achieved by computing a sequence of ‘hidden’ states $h_1,h_2,…,h_T$ which can be viewed as successive encodings of relevant information from past observations that will be useful for future predictions. See the figure below for a cartoon illustration. The variables are related using a simple network defined by the equations:\n",
    "                                    \n",
    "$$h_t=tanh⁡(W_{hx} x_t+W_{hh} h_{t-1}+b_h )\\\\\n",
    "y_t = \\sigma(W_{yh} h_t+b_y  )$$\n",
    "where both tanh and the sigmoid function, $\\sigma(\\cdot)$, are applied elementwise. The model is parameterized by an input weight matrix $W_{hx}$, recurrent weight matrix $W_{hh}$, initial state $h_0$, and readout weight matrix W_yh. Biases for latent and readout units are given by $b_h$  and $b_y$. \n",
    "![rnn.png](attachment:rnn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input and Output\n",
    "##### One-hot encoding input\n",
    "In order to train an RNN or LSTM on student interactions, it is necessary to convert those interactions into a sequence of fixed length input vectors $x_t$.  We transform the question numbers and corresponding response into one-hot encodings.  For instance, we have three questions 1,2,3 with the corresponding response 0, 1,1 (0 means not correct and 1 means correct).  \n",
    "1 2 3\n",
    "0 1 1\n",
    "Then the questions with corresponding responses can be transformed into 000 100, 010 000, 001 000. Each one-hot encoding dimension is double size of the max question number. The questions starts from 1 (the largest question number is 3 in the above example and the dimension of one-hot encoding is 3*2: see 000 100). If a question is answered correctly, then ‘1’ will assigned in the first 3 digitals, otherwise, it is assigned in the last 3 digitals. \n",
    "The input is [[000 100], [010 000], [001 000]].\n",
    "\n",
    "##### Embedding input\n",
    "In the above example, the questions with the responses are transformed into one-hot encodings, which are easy to understand. However, in case of large number of questions, the length of the one-hot encoding is large and the input composed by the one-hot encodings is sparse. This may lead to time consuming when training RNN or LSTM models.\n",
    "\n",
    "Instead of transforming the question numbers with responses into an one-hot encoding, we can first transform them into a integer, and then transform the integer into a embedding vector which size could be much smaller than the length of one-hot encoding. Still we consider the above example: we have three questions 1,2,3 with the corresponding response 0, 1,1 (0 means not correct and 1 means correct).  \n",
    "1 2 3\n",
    "0 1 1\n",
    "We transform the three questions with corresponding responses as follows:\n",
    "                                $$1 + 0*3 = 1$$     \n",
    "                                $$2 + 1*3 = 5 $$  \n",
    "                                $$3 + 1*3 = 6$$     \n",
    "Then we have invertible unique numbers 1, 5, 6, which can be transformed back to the question numbers and responses. Then in the next step, we can apply Python package to transform these unique numbers to some embedding. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output\n",
    "The DKT model produce the probability for mastering all the questions which may be asked in the next step:\n",
    "Here is the example:\n",
    "\n",
    "1 2 3 2 3          \n",
    "0 1 0 1 1 \n",
    "\n",
    "Then the corresponding one-hot encodings and the corresponding outputs of the DKT are \n",
    "\n",
    "000 100 (question 1 answered incorrect) $\\hspace{0.2cm}$ $p_{11},p_{12},p_{13}$\n",
    "\n",
    "010 000 (question 2 answered correct)  $\\hspace{0.45cm}$  $p_{21},p_{22},p_{23}$  \n",
    "\n",
    "000 001 (question 3 answered incorrect) $\\hspace{0.2cm}$ $p_{31},p_{32},p_{33}$ \n",
    "\n",
    "010 000 (question 2 answered correct)  $\\hspace{0.4cm}$   $p_{41},p_{42},p_{43}$ \n",
    "\n",
    "001 000 (question 3 answered correct) \n",
    "\n",
    "$\\hspace{0.3cm}$  $p_{11}, p_{12}, p_{13}$ are the probability of answering next questions correctly when next question is question 1, question 2 or question 3 with question 1 answered incorrectly. Similarly, $p_{21}$, $p_{22}$, $p_{23}$ are the probability of answering next questions correctly when next question is question 1, question 2 or question 3 with questions 1 and 2 answered incorrectly and correctly respectively. This explanation can be extended to the case with embedding input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import argparse\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import logging\n",
    "from functools import partial\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.utils.data as Data\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_df = pd.read_csv(\"data/assist2015_train.csv\",header=None,sep='\\t')\n",
    "test_df = pd.read_csv(\"data/assist2015_test.csv\", header=None, sep='\\t')\n",
    "train_len = len(train_df)\n",
    "test_len = len(test_df)\n",
    "\n",
    "train_values = train_df[0].str.split(',').values\n",
    "train_flattened_values = [item for sublist in train_values for item in sublist]\n",
    "train_set = map(int,list(set(train_flattened_values)))\n",
    "train_list = sorted(train_set)\n",
    "\n",
    "test_values = test_df[0].str.split(',').values\n",
    "test_flattened_values = [item for sublist in test_values for item in sublist]\n",
    "test_set = map(int,list(set(test_flattened_values)))\n",
    "test_list = sorted(test_set)\n",
    "\n",
    "num_skills = len(train_list)\n",
    "\n",
    "print(num_skills) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(df, n_skill, max_step=64):\n",
    "    stus_ques = []\n",
    "    stus_ans = []\n",
    "    stus_ques_ans = []\n",
    "    mask = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        ques = df[0][i].split(\",\")\n",
    "        ans = df[1][i].split(\",\")\n",
    "        ques = list(map(int, ques))\n",
    "        ans = list(map(int, ans))\n",
    "        ques_ans = list(np.array(ques) + np.array(ans) * n_skill)\n",
    "        \n",
    "        len_list = len(ques)\n",
    "        num_segments = (len_list + max_step - 1) // max_step  # Calculate number of segments more efficiently\n",
    "         \n",
    "        \n",
    "        for j in range(num_segments):\n",
    "            start_idx = j * max_step\n",
    "            end_idx = min((j + 1) * max_step, len_list)\n",
    "\n",
    "            segment_ques = ques[start_idx:end_idx] + [n_skill] * (max_step - (end_idx - start_idx))  \n",
    "            segment_ans = ans[start_idx:end_idx] + [-1] * (max_step - (end_idx - start_idx))  \n",
    "            segment_ques_ans = ques_ans[start_idx:end_idx-1] + [n_skill * 2]* (max_step - (end_idx - start_idx)+1)\n",
    "            segment_mask = list(np.ones((end_idx-start_idx))) + [0]* (max_step - (end_idx - start_idx))\n",
    "            \n",
    "            stus_ques.append(segment_ques)\n",
    "            stus_ans.append(segment_ans)\n",
    "            stus_ques_ans.append(segment_ques_ans)\n",
    "            mask.append(segment_mask)\n",
    "    \n",
    "    return np.array(stus_ques), np.array(stus_ans), np.array(stus_ques_ans), np.array(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_ques, train_ans, train_ques_ans, train_mask = getData(train_df,100,max_step = 64)\n",
    "test_ques, test_ans, test_ques_ans, test_mask = getData(test_df,100,max_step = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DKTDataSet(Dataset):\n",
    "    def __init__(self,ques,ans,ques_ans,mask,num_skill,max_step=64):\n",
    "        self.ques = ques\n",
    "        self.ans = ans\n",
    "        self.ques_ans = ques_ans\n",
    "        self.mask = mask\n",
    "        self.num_skill = num_skill\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ques)    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        qu_ids = torch.LongTensor(self.ques[index])\n",
    "        an_resps = self.ans[index]\n",
    "        qu_resps = self.ques_ans[index]\n",
    "        mask_res = self.mask[index]\n",
    "         \n",
    "        return (\n",
    "            torch.cat((torch.LongTensor([2 * self.num_skill]), torch.LongTensor(qu_resps[:-1]))),\n",
    "            qu_ids.view(-1, 1),\n",
    "            torch.LongTensor(an_resps),\n",
    "            torch.LongTensor(mask_res),\n",
    "        )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\"\"\"\n",
    "    Paper reference: Deep Knowledge Tracing (https://arxiv.org/abs/1506.05908)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DKT(nn.Module):\n",
    "    def __init__(self,embed_dim,input_dim,hidden_dim,layer_num,output_dim,dropout,device=\"cpu\",cell_type=\"lstm\"):\n",
    "    \n",
    "        super(DKT, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.output_dim = output_dim + 1\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "        self.cell_type = cell_type\n",
    "        self.rnn = None\n",
    "\n",
    "        self.skill_embedding = nn.Embedding(self.input_dim, self.embed_dim, padding_idx=self.input_dim - 1)\n",
    "\n",
    "        if cell_type.lower() == \"lstm\":\n",
    "            self.rnn = nn.LSTM(self.embed_dim,self.hidden_dim,self.layer_num,batch_first=True,dropout=self.dropout)\n",
    "        elif cell_type.lower() == \"rnn\":\n",
    "            self.rnn = nn.RNN(self.embed_dim,self.hidden_dim,self.layer_num,batch_first=True,dropout=self.dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "\n",
    "    def forward(self,   ques_ans, state_in=None):\n",
    "\n",
    "        ques_ans = self.skill_embedding(ques_ans)\n",
    "        h0 = torch.zeros((self.layer_num, ques_ans.size(0), self.hidden_dim), device=self.device)\n",
    "        c0 = torch.zeros((self.layer_num, ques_ans.size(0), self.hidden_dim), device=self.device)\n",
    "\n",
    "        if state_in is None:\n",
    "            state_in = (h0, c0)\n",
    "\n",
    "        state, state_out = self.rnn(ques_ans, state_in)\n",
    "        logits = self.fc(state)\n",
    "        return logits, state_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "\n",
    "\n",
    "class DKTLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DKTLoss, self).__init__()\n",
    "         \n",
    "\n",
    "    def forward(self, logits, ans, qu_ids, mask, device=\"cpu\"):\n",
    "        preds = torch.sigmoid(logits)\n",
    "         \n",
    "        preds = torch.gather(preds, dim=2, index=qu_ids)\n",
    "         \n",
    "        preds = torch.squeeze(preds)\n",
    "        preds_ex_1st_col = preds[:,1:]\n",
    "        \n",
    "        ans_ex_1st_col = ans[:,1:]\n",
    "        \n",
    "        ones = torch.ones(ans.size(), device=device)\n",
    "        ones_ex_1st_col = ones[:,1:]\n",
    "        mask_ex_1st_col = mask[:,1:]\n",
    "        \n",
    "        total = torch.sum(mask) + 1\n",
    "        loss = -torch.sum(\n",
    "            mask_ex_1st_col * ans_ex_1st_col * torch.log(preds_ex_1st_col)\n",
    "            + mask_ex_1st_col * (ones_ex_1st_col - ans_ex_1st_col) * torch.log(ones_ex_1st_col - preds_ex_1st_col)\n",
    "        )\n",
    "\n",
    "         \n",
    "        loss = loss / total\n",
    "\n",
    "         \n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and evalution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import (roc_auc_score,precision_recall_fscore_support,accuracy_score)\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def train_epoch(model, train_iterator, optim, criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    for i, (ques_ans, ques_id, labels, mask) in enumerate(train_iterator):\n",
    "        ques_ans, ques_id, labels, mask = (ques_ans.to(device),ques_id.to(device),labels.to(device),mask.to(device))\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        logits, _ = model(ques_ans)\n",
    "        loss = criterion(logits, labels, ques_id, mask, device=device)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "\n",
    "def eval_epoch(model, test_iterator, criterion, eval_func,data_type, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = []\n",
    "    preds, binary_preds, targets = [], [], []\n",
    "    for i, (ques_ans, ques_id, labels, mask) in enumerate(test_iterator):\n",
    "        ques_ans, ques_id, labels, mask = (ques_ans.to(device),ques_id.to(device),labels.to(device),mask.to(device))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(ques_ans)\n",
    "\n",
    "        loss = criterion(logits, labels, ques_id, mask, device=device)\n",
    "        eval_loss.append(loss.detach().item())\n",
    "\n",
    "        mask = mask.eq(1)\n",
    "        \n",
    "        \n",
    "        pred, binary_pred, target = eval_func(logits, ques_id, labels, mask)\n",
    "        preds.append(pred)\n",
    "        binary_preds.append(binary_pred)\n",
    "        targets.append(target)\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    binary_preds = np.concatenate(binary_preds)\n",
    "    targets = np.concatenate(targets)\n",
    "\n",
    "    auc_value = roc_auc_score(targets, preds)\n",
    "    accuracy = accuracy_score(targets, binary_preds)\n",
    "    precision, recall, f_score, _ = precision_recall_fscore_support(\n",
    "        targets, binary_preds\n",
    "    )\n",
    "    pos_rate = np.sum(targets) / float(len(targets))\n",
    "    print(data_type,\n",
    "        \"auc={0}, accuracy={1}, precision={2}, recall={3}, fscore={4}, pos_rate={5}\".format(\n",
    "            auc_value, accuracy, precision, recall, f_score, pos_rate\n",
    "        )\n",
    "    )\n",
    "    return auc_value\n",
    "\n",
    "\n",
    "def dkt_predict(logits, ques_id):\n",
    "    preds = torch.sigmoid(logits)\n",
    "    preds = torch.gather(preds, dim=2, index=ques_id)\n",
    "    preds = torch.squeeze(preds)\n",
    "    binary_preds = torch.round(preds)\n",
    "    return (\n",
    "        preds.view(preds.size()[0], preds.size()[1]),\n",
    "        binary_preds.view(preds.size()[0], preds.size()[1]),\n",
    "    )    \n",
    "    \n",
    "def dkt_eval(logits, ques_id, targets, mask):\n",
    "    pred, binary_pred = dkt_predict(logits, ques_id)\n",
    "    pred_ex_1st_col = pred[:,1:]\n",
    "    binary_pred_ex_1st_col = binary_pred[:,1:] \n",
    "    mask_ex_1st_col = mask[:,1:]\n",
    "    targets_ex_1st_col = targets[:,1:]\n",
    "    pred = torch.masked_select(pred_ex_1st_col, mask_ex_1st_col).detach().numpy()\n",
    "    binary_pred = torch.masked_select(binary_pred_ex_1st_col, mask_ex_1st_col).detach().numpy()\n",
    "    target = torch.masked_select(targets_ex_1st_col, mask_ex_1st_col).detach().numpy()\n",
    "    return pred, binary_pred, target\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train = DKTDataSet(train_ques, train_ans, train_ques_ans, train_mask,100)\n",
    "     \n",
    "     \n",
    "    test = DKTDataSet(test_ques, test_ans, test_ques_ans, test_mask,100)\n",
    "    \n",
    "    \n",
    "    train_dataloader = DataLoader(train,batch_size=args.batch_size,num_workers=args.num_worker,shuffle=True)\n",
    "    \n",
    "    \n",
    "    test_dataloader = DataLoader(test,batch_size=args.batch_size*2,num_workers=args.num_worker,shuffle=False)\n",
    "\n",
    "    dkt = DKT(args.embed_dim,\n",
    "              args.num_skill * 2 + 1,\n",
    "              args.hidden_dim,\n",
    "              args.layer_num,\n",
    "              args.num_skill,\n",
    "              args.dropout,\n",
    "              device=device)\n",
    "    optimizer = torch.optim.Adam(dkt.parameters(), lr=args.learning_rate)\n",
    "    loss_func = DKTLoss()\n",
    "\n",
    "    dkt.to(device)\n",
    "    loss_func.to(device)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "    over_fit = 0\n",
    "    last_auc = 0\n",
    "    for epoch in range(args.epoch):\n",
    "        train_epoch(dkt, train_dataloader, optimizer, loss_func,device)\n",
    "        print('-------------------------------------------------------------------------------')\n",
    "        print('-------------------------------------------------------------------------------')\n",
    "#         data_type = 'train_data'\n",
    "#         eval_epoch(dkt, train_dataloader, loss_func, dkt_eval,data_type, device)\n",
    "#         print('-------------')\n",
    "        data_type = 'test_data'\n",
    "        auc_value = eval_epoch(dkt, test_dataloader, loss_func, dkt_eval,data_type, device)\n",
    "        scheduler.step()\n",
    "#         if auc_value > last_auc:\n",
    "#             last_auc = auc_value\n",
    "#             over_fit = 0\n",
    "#         else:\n",
    "#             over_fit += 1\n",
    "\n",
    "\n",
    "#         if over_fit >= 2:\n",
    "#             print(\"early stop epoch \", epoch)\n",
    "#             break\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "test_data auc=0.723840185234873, accuracy=0.754836831176394, precision=[0.57490953 0.77378593], recall=[0.21114032 0.94530781], fscore=[0.30885212 0.85099011], pos_rate=0.7405619535817454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "test_data auc=0.7278529462594236, accuracy=0.7551050119148871, precision=[0.56924985 0.77691024], recall=[0.23039664 0.93892395], fscore=[0.32802809 0.85026821], pos_rate=0.7405619535817454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "test_data auc=0.7294936047358811, accuracy=0.7561930594824878, precision=[0.58504252 0.7735139 ], recall=[0.2072418  0.94850491], fscore=[0.30606503 0.85211814], pos_rate=0.7405619535817454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "test_data auc=0.7306674051806732, accuracy=0.7556796849259438, precision=[0.56917467 0.77855963], recall=[0.23972947 0.93643042], fscore=[0.33736492 0.85022875], pos_rate=0.7405619535817454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "test_data auc=0.730665560703668, accuracy=0.7553195565056816, precision=[0.56412305 0.78018201], recall=[0.25021412 0.93227108], fscore=[0.34666612 0.84947276], pos_rate=0.7405619535817454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "test_data auc=0.7309486031257071, accuracy=0.7555187764828479, precision=[0.56949587 0.77795046], recall=[0.23621489 0.93744439], fscore=[0.33392481 0.85028271], pos_rate=0.7405619535817454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "test_data auc=0.7302995351511525, accuracy=0.7559861771985074, precision=[0.56967809 0.77917356], recall=[0.2430373  0.93568546], fscore=[0.34071712 0.85028724], pos_rate=0.7405619535817454\n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "test_data auc=0.7299690092110327, accuracy=0.7545763127447149, precision=[0.56135525 0.7794886 ], recall=[0.24711303 0.93235385], fscore=[0.34316299 0.84909589], pos_rate=0.7405619535817454\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arg_parser = argparse.ArgumentParser(description=\"train dkt model\")\n",
    "arg_parser.add_argument(\"--learning_rate\",dest=\"learning_rate\",default=0.001,type=float,required=False)\n",
    "arg_parser.add_argument(\"--batch_size\",dest=\"batch_size\",default=64,type=int,required=False)\n",
    "arg_parser.add_argument(\"--num_skill\",dest=\"num_skill\",default=num_skills,type=int,required=False)\n",
    "arg_parser.add_argument(\"--embed_dim\",dest=\"embed_dim\",default=100,type=int,required=False)\n",
    "arg_parser.add_argument(\"--hidden_dim\",dest=\"hidden_dim\",default=100,type=int,required=False)\n",
    "arg_parser.add_argument(\"--layer_num\",dest=\"layer_num\",default=1,type=int,required=False)\n",
    "arg_parser.add_argument(\"--output_dim\",dest=\"output_dim\",default=100,type=int,required=False)\n",
    "arg_parser.add_argument(\"--dropout\",dest=\"dropout\",default=0.0,type=float,required=False)\n",
    "arg_parser.add_argument(\"--cell_type\",dest=\"cell_type\",default=\"lstm\",type=str,required=False)\n",
    "arg_parser.add_argument(\"--epoch\",dest=\"epoch\",default=10,type=int,required=False)\n",
    "arg_parser.add_argument(\"--num_worker\",dest=\"num_worker\",default=0,type=int,required=False)\n",
    "\n",
    "args,unknown_args = arg_parser.parse_known_args()\n",
    "run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
